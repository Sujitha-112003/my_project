{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6490520,"sourceType":"datasetVersion","datasetId":2884477}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Rescaling, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.optimizers import RMSprop\nfrom keras.optimizers import Adagrad\nfrom keras.optimizers import Adadelta\nfrom keras.optimizers import Nadam\nfrom keras.optimizers import Ftrl\n# from keras.optimizers import ProximalSGD\nfrom keras.optimizers import Adamax","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:50.386904Z","iopub.execute_input":"2023-12-02T16:06:50.387584Z","iopub.status.idle":"2023-12-02T16:06:50.395094Z","shell.execute_reply.started":"2023-12-02T16:06:50.387541Z","shell.execute_reply":"2023-12-02T16:06:50.393902Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_height,img_width=224,224\nbatch_size=32\ndata_dir = \"/kaggle/input/apple-disease-dataset-original/Original Data/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:51.643007Z","iopub.execute_input":"2023-12-02T16:06:51.643693Z","iopub.status.idle":"2023-12-02T16:06:51.647938Z","shell.execute_reply.started":"2023-12-02T16:06:51.643648Z","shell.execute_reply":"2023-12-02T16:06:51.646909Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Creating an ImageDataGenerator with augmentation\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2  # Set the validation split\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:52.591549Z","iopub.execute_input":"2023-12-02T16:06:52.591902Z","iopub.status.idle":"2023-12-02T16:06:52.596831Z","shell.execute_reply.started":"2023-12-02T16:06:52.591876Z","shell.execute_reply":"2023-12-02T16:06:52.595786Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Creating an ImageDataGenerator with augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2  # Set the validation split\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:54.051251Z","iopub.execute_input":"2023-12-02T16:06:54.052027Z","iopub.status.idle":"2023-12-02T16:06:54.056818Z","shell.execute_reply.started":"2023-12-02T16:06:54.051994Z","shell.execute_reply":"2023-12-02T16:06:54.055686Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    data_dir + \"train\",\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:54.377619Z","iopub.execute_input":"2023-12-02T16:06:54.378450Z","iopub.status.idle":"2023-12-02T16:06:57.528711Z","shell.execute_reply.started":"2023-12-02T16:06:54.378418Z","shell.execute_reply":"2023-12-02T16:06:57.527983Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 6218 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"validation_generator = train_datagen.flow_from_directory(\n    data_dir + \"train\",\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:57.530596Z","iopub.execute_input":"2023-12-02T16:06:57.531149Z","iopub.status.idle":"2023-12-02T16:06:57.788491Z","shell.execute_reply.started":"2023-12-02T16:06:57.531111Z","shell.execute_reply":"2023-12-02T16:06:57.787713Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 1553 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test dataset generator (without data augmentation)\ntest_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n    data_dir + \"test\",\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    shuffle=False,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:57.789606Z","iopub.execute_input":"2023-12-02T16:06:57.789906Z","iopub.status.idle":"2023-12-02T16:06:58.163349Z","shell.execute_reply.started":"2023-12-02T16:06:57.789878Z","shell.execute_reply":"2023-12-02T16:06:58.162614Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 1943 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the class names\nclass_names = list(train_generator.class_indices.keys())\nprint(\"Class Names:\", class_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:58.165176Z","iopub.execute_input":"2023-12-02T16:06:58.165465Z","iopub.status.idle":"2023-12-02T16:06:58.170243Z","shell.execute_reply.started":"2023-12-02T16:06:58.165440Z","shell.execute_reply":"2023-12-02T16:06:58.169410Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Class Names: ['Apple Scab', 'Black Rot', 'Cedar Apple Rust', 'Healthy']\n","output_type":"stream"}]},{"cell_type":"code","source":"VGG16_model = Sequential()\n\npretrained_model = tf.keras.applications.VGG16(\n                    include_top=False,\n                    input_shape=(224, 224, 3),\n                    pooling='avg',\n                    classes=4,\n                    weights='imagenet'\n                   )\n\nfor layer in pretrained_model.layers:\n    layer.trainable = False\n\nVGG16_model.add(pretrained_model)\nVGG16_model.add(Flatten())\nVGG16_model.add(BatchNormalization())\nVGG16_model.add(Dense(512, activation='relu'))\nVGG16_model.add(BatchNormalization())\nVGG16_model.add(Dropout(0.5))  # Add dropout with a rate of 0.5\nVGG16_model.add(Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:06:58.171396Z","iopub.execute_input":"2023-12-02T16:06:58.171759Z","iopub.status.idle":"2023-12-02T16:07:03.483352Z","shell.execute_reply.started":"2023-12-02T16:06:58.171734Z","shell.execute_reply":"2023-12-02T16:07:03.482572Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"VGG16_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:07:12.182755Z","iopub.execute_input":"2023-12-02T16:07:12.183476Z","iopub.status.idle":"2023-12-02T16:07:12.212492Z","shell.execute_reply.started":"2023-12-02T16:07:12.183439Z","shell.execute_reply":"2023-12-02T16:07:12.211454Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg16 (Functional)          (None, 512)               14714688  \n                                                                 \n flatten (Flatten)           (None, 512)               0         \n                                                                 \n batch_normalization (Batch  (None, 512)               2048      \n Normalization)                                                  \n                                                                 \n dense (Dense)               (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 4)                 2052      \n                                                                 \n=================================================================\nTotal params: 14983492 (57.16 MB)\nTrainable params: 266756 (1.02 MB)\nNon-trainable params: 14716736 (56.14 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate = 0.001  # Adjust the learning rate as needed\noptimizer = Adam(learning_rate=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:07:57.629729Z","iopub.execute_input":"2023-12-02T16:07:57.630139Z","iopub.status.idle":"2023-12-02T16:07:57.637345Z","shell.execute_reply.started":"2023-12-02T16:07:57.630105Z","shell.execute_reply":"2023-12-02T16:07:57.636168Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"epochs=100","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:07:59.114530Z","iopub.execute_input":"2023-12-02T16:07:59.115168Z","iopub.status.idle":"2023-12-02T16:07:59.119186Z","shell.execute_reply.started":"2023-12-02T16:07:59.115132Z","shell.execute_reply":"2023-12-02T16:07:59.118161Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"VGG16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:07:59.832293Z","iopub.execute_input":"2023-12-02T16:07:59.832669Z","iopub.status.idle":"2023-12-02T16:07:59.850607Z","shell.execute_reply.started":"2023-12-02T16:07:59.832641Z","shell.execute_reply":"2023-12-02T16:07:59.849654Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  # You can use 'accuracy' or other metrics based on your preference\n    patience=10,           # Number of epochs with no improvement after which training will be stopped\n    verbose=1,\n    mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:08:11.901083Z","iopub.execute_input":"2023-12-02T16:08:11.901821Z","iopub.status.idle":"2023-12-02T16:08:11.908839Z","shell.execute_reply.started":"2023-12-02T16:08:11.901787Z","shell.execute_reply":"2023-12-02T16:08:11.907806Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"history = VGG16_model.fit(\n        train_generator,\n        validation_data=validation_generator,\n        epochs=epochs,\n        callbacks= [early_stopping]\n     )","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:08:16.192886Z","iopub.execute_input":"2023-12-02T16:08:16.193264Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n195/195 [==============================] - 147s 683ms/step - loss: 0.3636 - accuracy: 0.8757 - val_loss: 0.5911 - val_accuracy: 0.7869\nEpoch 2/100\n195/195 [==============================] - 114s 585ms/step - loss: 0.1923 - accuracy: 0.9344 - val_loss: 0.1399 - val_accuracy: 0.9594\nEpoch 3/100\n195/195 [==============================] - 113s 579ms/step - loss: 0.1489 - accuracy: 0.9469 - val_loss: 0.0686 - val_accuracy: 0.9742\nEpoch 4/100\n195/195 [==============================] - 112s 575ms/step - loss: 0.1408 - accuracy: 0.9495 - val_loss: 0.0805 - val_accuracy: 0.9742\nEpoch 5/100\n195/195 [==============================] - 112s 575ms/step - loss: 0.1212 - accuracy: 0.9566 - val_loss: 0.0700 - val_accuracy: 0.9762\nEpoch 6/100\n195/195 [==============================] - 113s 580ms/step - loss: 0.1096 - accuracy: 0.9595 - val_loss: 0.0600 - val_accuracy: 0.9813\nEpoch 7/100\n195/195 [==============================] - 113s 578ms/step - loss: 0.1046 - accuracy: 0.9641 - val_loss: 0.0642 - val_accuracy: 0.9762\nEpoch 8/100\n195/195 [==============================] - 112s 575ms/step - loss: 0.0873 - accuracy: 0.9678 - val_loss: 0.0630 - val_accuracy: 0.9755\nEpoch 9/100\n195/195 [==============================] - 112s 574ms/step - loss: 0.0943 - accuracy: 0.9657 - val_loss: 0.0591 - val_accuracy: 0.9800\nEpoch 10/100\n195/195 [==============================] - 112s 574ms/step - loss: 0.0848 - accuracy: 0.9704 - val_loss: 0.0528 - val_accuracy: 0.9807\nEpoch 11/100\n195/195 [==============================] - 112s 575ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 0.0462 - val_accuracy: 0.9826\nEpoch 12/100\n195/195 [==============================] - 111s 570ms/step - loss: 0.0743 - accuracy: 0.9728 - val_loss: 0.0631 - val_accuracy: 0.9781\nEpoch 13/100\n195/195 [==============================] - 113s 579ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.0479 - val_accuracy: 0.9820\nEpoch 14/100\n195/195 [==============================] - 112s 577ms/step - loss: 0.0806 - accuracy: 0.9723 - val_loss: 0.0734 - val_accuracy: 0.9768\nEpoch 15/100\n195/195 [==============================] - 111s 571ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.0464 - val_accuracy: 0.9813\nEpoch 16/100\n195/195 [==============================] - 112s 572ms/step - loss: 0.0723 - accuracy: 0.9743 - val_loss: 0.0434 - val_accuracy: 0.9884\nEpoch 17/100\n195/195 [==============================] - 111s 571ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.0536 - val_accuracy: 0.9781\nEpoch 18/100\n195/195 [==============================] - 112s 572ms/step - loss: 0.0794 - accuracy: 0.9711 - val_loss: 0.0550 - val_accuracy: 0.9820\nEpoch 19/100\n195/195 [==============================] - 111s 570ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.0557 - val_accuracy: 0.9794\nEpoch 20/100\n195/195 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9751","output_type":"stream"}]},{"cell_type":"code","source":"steps = len(test_generator)\ntest_loss, test_accuracy = VGG16_model.evaluate(test_generator, steps=steps)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\n\npredictions = VGG16_model.predict(test_generator)\npredicted_labels = np.argmax(predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Assuming `test_generator` is your test data generator\nnum_batches = len(test_generator)\nbatch_size = test_generator.batch_size\n\ntrue_labels = []\npredicted_labels = []\npredicted_probs = []\n\n# Generate predictions in batches\nfor i in range(num_batches):\n    data_batch, labels_batch = next(test_generator)\n\n    true_labels.extend(np.argmax(labels_batch, axis=1))  # Extracting class indices without calling `numpy()`\n\n    predictions_batch = VGG16_model.predict(data_batch)\n    predicted_labels.extend(np.argmax(predictions_batch, axis=1))\n    predicted_probs.extend(predictions_batch)\n\ntrue_labels = np.array(true_labels)\npredicted_labels = np.array(predicted_labels)\npredicted_probs = np.concatenate(predicted_probs)\n\nclass_names = list(test_generator.class_indices.keys())\n\n# Classification Report\nreport = classification_report(true_labels, predicted_labels, target_names=class_names)\nprint(\"Classification Report:\")\nprint(report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Access the training history from the history object\ntraining_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n# You can also access other metrics like accuracy, etc. if you have them.\n\n# Create a plot to visualize the training and validation loss\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(training_loss) + 1), training_loss, label='Training Loss')\nplt.plot(range(1, len(validation_loss) + 1), validation_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Access the training history from the history object\ntraining_accuracy = history.history['accuracy']\nvalidation_accuracy = history.history['val_accuracy']\n# You can also access other metrics like accuracy, etc. if you have them.\n\n# Create a plot to visualize the training and validation loss\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(training_accuracy) + 1), training_accuracy, label='Training accuracy')\nplt.plot(range(1, len(validation_accuracy) + 1), validation_accuracy, label='Validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}